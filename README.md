# Ayushman Singh

Applied Research Engineer working on large-scale LLM inference and ML systems.

My work focuses on bridging research ideas and production systems, with an emphasis on
GPU-level performance optimization and inference-time techniques.

## Areas of focus
- LLM inference and serving systems
- GPU performance optimization (Triton / CUDA)
- Quantization and speculative decoding
- KV-cache optimization and batching strategies
- Production GenAI infrastructure

## Writing
I occasionally write about GPU architecture, inference optimization, and ML systems:
- https://www.ayushmansingh.com

## Contact
- LinkedIn: https://www.linkedin.com/in/ayushmansingh

<!--
**ayush1399/ayush1399** is a ✨ _special_ ✨ repository because its `README.md` (this file) appears on your GitHub profile.
-->
